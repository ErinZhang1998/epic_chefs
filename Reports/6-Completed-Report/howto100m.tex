With the aim of building more robust joint embedding space, we experimented Howto100m retrieval model on EPIC-KITCHENS dataset under different settings, as explained in Section~\ref{section:howto100m-experiments}. From Table \ref{table:howto100m_label}, we see a strong positive correlation between richness of text and performance of retrieval. With plain verbs as label, the retrieval result is orders of magnitudes worse than other settings. By adding more textual information to just verb, we see improvements in median-rank of true label and recall scores in both \textit{Narration} (current narration) and \textit{Narration+Context} (previous and current narrations). The reason that using noun helps is more obvious: for verbs that cannot be easily visualized or doesn't correspond to a single action (e.g. \textit{take}), the less ambiguous object can narrow down the search space for appropriate verbs. 

In addition to text input, length of segments also affects performance (see Table \ref{table:howto100m_seg_threshold}). By only considering segments that contain more than \textit{Segment Threshold} number of features, we found that the longer the segments, the better the retrieval performance. Because the model uses maxpooling across video features from the same segment, the final video feature for the segment contains the most eminent features within the segment. However, since ground truth and video feature are not perfectly aligned (videos are downsampled before feature extraction), there are inevitable noise at the boundary of segments. Thus the shorter the segment, the noisier the video feature.   